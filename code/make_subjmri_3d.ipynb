{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nsd_access import NSDAccess\n",
    "import scipy.io\n",
    "\n",
    "from config import NSD_ROOT_DIR, DATA_ROOT_DIR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--subject\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"subject name: subj01 or subj02  or subj05  or subj07 for full-data subjects \",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "# name : each or ave\n",
    "def write_index(sharedix, stims, name, save_dir):\n",
    "    feats = []\n",
    "    tr_idx = np.zeros(len(stims))\n",
    "    for idx, s in tqdm(enumerate(stims)): \n",
    "        if s in sharedix:\n",
    "            tr_idx[idx] = 0\n",
    "        else:\n",
    "            tr_idx[idx] = 1    \n",
    "        feats.append(s)\n",
    "    \n",
    "    feats = np.stack(feats)\n",
    "\n",
    "    feats_tr = feats[tr_idx==1]\n",
    "    feats_te = feats[tr_idx==0]\n",
    "\n",
    "    np.save(f'{save_dir}/index_{name}_tr.npy',feats_tr)\n",
    "    np.save(f'{save_dir}/index_{name}_te.npy',feats_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27750it [00:00, 253037.50it/s]\n",
      "9841it [00:00, 287348.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# opt = parse_args()\n",
    "\n",
    "# subject = opt.subject\n",
    "subject = 'subj01'\n",
    "atlasname = 'streams'\n",
    "atlasname = 'nsdgeneral'\n",
    "# atlasname = 'HCP_MMP1'\n",
    "\n",
    "nsda = NSDAccess(NSD_ROOT_DIR)\n",
    "nsd_expdesign = scipy.io.loadmat(os.path.join(NSD_ROOT_DIR, 'nsddata/experiments/nsd/nsd_expdesign.mat'))\n",
    "\n",
    "# Note that most of nsd_expdesign indices are 1-base index!\n",
    "# This is why subtracting 1\n",
    "sharedix = nsd_expdesign['sharedix'] -1 \n",
    "\n",
    "behs = pd.DataFrame()\n",
    "for i in range(1,38):\n",
    "    beh = nsda.read_behavior(subject=subject, \n",
    "                            session_index=i)\n",
    "    behs = pd.concat((behs,beh))\n",
    "\n",
    "# Caution: 73KID is 1-based! https://cvnlab.slite.page/p/fRv4lz5V2F/Behavioral-data\n",
    "stims_unique = behs['73KID'].unique() - 1\n",
    "stims_all = behs['73KID'] - 1\n",
    "\n",
    "savedir = os.path.join(DATA_ROOT_DIR, f'mrifeat/{subject}/')\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(f'{savedir}/{subject}_stims.npy'):\n",
    "    np.save(f'{savedir}/{subject}_stims.npy',stims_all)\n",
    "    np.save(f'{savedir}/{subject}_stims_ave.npy',stims_unique)\n",
    "\n",
    "write_index(sharedix, stims_all, 'each', savedir)\n",
    "write_index(sharedix, stims_unique, 'ave', savedir)\n",
    "# exit(0)\n",
    "\n",
    "atlas = nsda.read_atlas_results(subject=subject, atlas=atlasname, data_format='func1pt8mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 104, 83)\n",
      "{'unknown': 0, 'nsdgeneral': 1}\n",
      "(81, 104, 83)\n",
      "12 72 3 48 27 68\n",
      "110700\n"
     ]
    }
   ],
   "source": [
    "print(atlas[0].shape)\n",
    "print(atlas[1])\n",
    "\n",
    "def get_range(atlas):\n",
    "    i0 = 200\n",
    "    i1 = 0\n",
    "    j0 = 200\n",
    "    j1 = 0\n",
    "    k0 = 200\n",
    "    k1 = 0\n",
    "    for i in range(atlas[0].shape[0]):\n",
    "        for j in range(atlas[0].shape[1]):\n",
    "            for k in range(atlas[0].shape[2]):\n",
    "                if atlas[0][i,j,k] > 0:\n",
    "                    i0 = min(i0, i)\n",
    "                    i1 = max(i1, i)\n",
    "                    j0 = min(j0, j)\n",
    "                    j1 = max(j1, j)\n",
    "                    k0 = min(k0, k)\n",
    "                    k1 = max(k1, k)\n",
    "    return i0, i1, j0, j1, k0, k1\n",
    "    \n",
    "# for s in ['subj01', 'subj02', 'subj05', 'subj07']:\n",
    "for s in ['subj01']:\n",
    "    atlas = nsda.read_atlas_results(subject=s, atlas=atlasname, data_format='func1pt8mm')\n",
    "    print(atlas[0].shape)\n",
    "    i0, i1, j0, j1, k0, k1 = get_range(atlas)\n",
    "    print(i0, i1, j0, j1, k0, k1)\n",
    "    print((i1 - i0) * (j1 - j0) * (k1 - k0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements > 0: 15724\n",
      "Number of elements >= 0: 107104\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "array = atlas[0]\n",
    "\n",
    "# 选择要绘制的切片的索引\n",
    "for slice_index in range(0, 0):\n",
    "\n",
    "    # 获取切片数据\n",
    "    slice_data = array[:, :, slice_index]\n",
    "\n",
    "    # 绘制切片\n",
    "    plt.imshow(slice_data, cmap='grey')\n",
    "    plt.colorbar()\n",
    "    plt.title('Slice at index {}'.format(slice_index))\n",
    "    plt.show()\n",
    "\n",
    "# 统计 array 中 >-1 的元素个数\n",
    "print('Number of elements > 0:', np.sum(array > 0))\n",
    "print('Number of elements >= 0:', np.sum(array >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# for v in range(1, 7):\n",
    "#     # 生成随机三维点\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     z = []\n",
    "#     for i in range(atlas[0].shape[0]):\n",
    "#         for j in range(atlas[0].shape[1]):\n",
    "#             for k in range(atlas[0].shape[2]):\n",
    "#                 if atlas[0][i,j,k] == v:\n",
    "#                     x.append(i)\n",
    "#                     y.append(j)\n",
    "#                     z.append(k)\n",
    "#                     break\n",
    "\n",
    "#     # 创建三维图形对象\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     # 绘制散点图\n",
    "#     ax.scatter(x, y, z, c='b', marker='o')\n",
    "\n",
    "#     # 设置坐标轴标签\n",
    "#     ax.set_xlabel('X')\n",
    "#     ax.set_ylabel('Y')\n",
    "#     ax.set_zlabel('Z')\n",
    "\n",
    "#     # 显示图形\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/maxinzhu/denghan/nsd/nsddata/ppdata/subj01/func1pt8mm/prf_angle.nii.gz\n",
      "\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (81, 104, 83)\n",
      "affine:\n",
      "[[  1.79999995   0.           0.         -72.        ]\n",
      " [  0.           1.79999995   0.         -92.69999695]\n",
      " [  0.           0.           1.79999995 -73.80000305]\n",
      " [  0.           0.           0.           1.        ]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3  81 104  83   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.        1.8       1.8       1.8       1.3333334 1.        1.\n",
      " 1.       ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 360\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b'none'\n",
      "qform_code      : unknown\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 0.0\n",
      "qoffset_y       : 0.0\n",
      "qoffset_z       : 0.0\n",
      "srow_x          : [  1.8   0.    0.  -72. ]\n",
      "srow_y          : [  0.    1.8   0.  -92.7]\n",
      "srow_z          : [  0.    0.    1.8 -73.8]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "\n",
      "[[[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mapper_results = nsda.read_mapper_results(subject=subject,\n",
    "                                        #   data_type='gain',\n",
    "                                        #   data_type='eccentricity',\n",
    "                                          data_format='func1pt8mm')\n",
    "print(mapper_results)\n",
    "print(mapper_results.get_fdata())\n",
    "# print(np.asanyarray(mapper_results.dataobj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading betas: 100%|██████████| 37/37 [11:43<00:00, 19.02s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,38), desc = 'reading betas'):\n",
    "    beta_trial = nsda.read_betas(subject=subject, \n",
    "                            session_index=i, \n",
    "                            trial_index=[], # empty list as index means get all for this session\n",
    "                            data_type='betas_fithrf_GLMdenoise_RR',\n",
    "                            data_format='func1pt8mm')\n",
    "    if i==1:\n",
    "        betas_all = beta_trial\n",
    "    else:\n",
    "        betas_all = np.concatenate((betas_all,beta_trial),0)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose\n",
    "betas_all[:, atlas[0].transpose(2,1,0) <= 0] = 0\n",
    "betas_all = betas_all[:,k0:k1+1,j0:j1+1,i0:i1+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27750, 42, 46, 61)\n"
     ]
    }
   ],
   "source": [
    "print(betas_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_all_ave = []\n",
    "for stim in stims_unique:\n",
    "    stim_mean = np.mean(betas_all[stims_all == stim,:],axis=0)\n",
    "    betas_all_ave.append(stim_mean)\n",
    "betas_all_ave = np.stack(betas_all_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27750, 42, 46, 61)\n",
      "(24980, 42, 46, 61)\n",
      "(982, 42, 46, 61)\n"
     ]
    }
   ],
   "source": [
    "print(betas_all.shape)\n",
    "\n",
    "betas_tr = []\n",
    "betas_te = []\n",
    "\n",
    "for idx,stim in enumerate(stims_all):\n",
    "    if stim in sharedix:\n",
    "        betas_te.append(betas_all[idx,:])\n",
    "    else:\n",
    "        betas_tr.append(betas_all[idx,:])\n",
    "\n",
    "betas_tr = np.stack(betas_tr)\n",
    "betas_te = np.stack(betas_te)    \n",
    "\n",
    "betas_ave_tr = []\n",
    "betas_ave_te = []\n",
    "for idx,stim in enumerate(stims_unique):\n",
    "    if stim in sharedix:\n",
    "        betas_ave_te.append(betas_all_ave[idx,:])\n",
    "    else:\n",
    "        betas_ave_tr.append(betas_all_ave[idx,:])\n",
    "\n",
    "betas_ave_tr = np.stack(betas_ave_tr)\n",
    "betas_ave_te = np.stack(betas_ave_te)    \n",
    "\n",
    "print(betas_tr.shape)\n",
    "print(betas_ave_te.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, h = betas_tr.shape[1], betas_tr.shape[2], betas_tr.shape[3]\n",
    "\n",
    "betas_tr = betas_tr.reshape(-1, n*m*h)\n",
    "betas_te = betas_te.reshape(-1, n*m*h)\n",
    "betas_ave_tr = betas_ave_tr.reshape(-1, n*m*h)\n",
    "betas_ave_te = betas_ave_te.reshape(-1, n*m*h)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "betas_tr = scaler.fit_transform(betas_tr)\n",
    "betas_te = scaler.transform(betas_te)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "betas_ave_tr = scaler.fit_transform(betas_ave_tr)\n",
    "betas_ave_te = scaler.transform(betas_ave_te)\n",
    "\n",
    "betas_tr = betas_tr.reshape(-1, n, m, h)\n",
    "betas_te = betas_te.reshape(-1, n, m, h)\n",
    "betas_ave_tr = betas_ave_tr.reshape(-1, n, m, h)\n",
    "betas_ave_te = betas_ave_te.reshape(-1, n, m, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 982/982 [00:21<00:00, 45.95it/s]\n",
      "100%|██████████| 24980/24980 [05:41<00:00, 73.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dir = os.path.join(savedir, f'betas_all_{atlasname}')\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(betas_ave_te.shape[0])):\n",
    "    np.save(f'{dir}/{i:06}_ave_te.npy',betas_ave_te[i])\n",
    "\n",
    "for i in tqdm(range(betas_tr.shape[0])):\n",
    "    np.save(f'{dir}/{i:06}_tr.npy',betas_tr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for roi,val in atlas[1].items():\n",
    "#     print(roi,val)\n",
    "#     if val == 0:\n",
    "#         print('SKIP')\n",
    "#         continue\n",
    "#     else:\n",
    "#         betas_roi = betas_all[:,atlas[0].transpose([2,1,0])==val]\n",
    "\n",
    "#     print(betas_roi.shape)\n",
    "    \n",
    "#     # Averaging for each stimulus\n",
    "#     betas_roi_ave = []\n",
    "#     for stim in stims_unique:\n",
    "#         stim_mean = np.mean(betas_roi[stims_all == stim,:],axis=0)\n",
    "#         betas_roi_ave.append(stim_mean)\n",
    "#     betas_roi_ave = np.stack(betas_roi_ave)\n",
    "#     print(betas_roi_ave.shape)\n",
    "    \n",
    "#     # Train/Test Split\n",
    "#     # ALLDATA\n",
    "    \n",
    "#     # AVERAGED DATA        \n",
    "#     betas_ave_tr = []\n",
    "#     betas_ave_te = []\n",
    "#     for idx,stim in enumerate(stims_unique):\n",
    "#         if stim in sharedix:\n",
    "#             betas_ave_te.append(betas_roi_ave[idx,:])\n",
    "#         else:\n",
    "#             betas_ave_tr.append(betas_roi_ave[idx,:])\n",
    "#     betas_ave_tr = np.stack(betas_ave_tr)\n",
    "#     betas_ave_te = np.stack(betas_ave_te)    \n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     betas_tr = scaler.fit_transform(betas_tr)\n",
    "#     betas_te = scaler.transform(betas_te)\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     betas_ave_tr = scaler.fit_transform(betas_ave_tr)\n",
    "#     betas_ave_te = scaler.transform(betas_ave_te)\n",
    "    \n",
    "#     # Save\n",
    "#     np.save(f'{savedir}/{subject}_{roi}_betas_tr.npy',betas_tr)\n",
    "#     np.save(f'{savedir}/{subject}_{roi}_betas_te.npy',betas_te)\n",
    "#     np.save(f'{savedir}/{subject}_{roi}_betas_ave_tr.npy',betas_ave_tr)\n",
    "#     np.save(f'{savedir}/{subject}_{roi}_betas_ave_te.npy',betas_ave_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
