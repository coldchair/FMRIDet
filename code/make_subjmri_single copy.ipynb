{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27750it [00:00, 278255.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24980,) (2770,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9841it [00:00, 284464.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8859,) (982,)\n",
      "14278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nsd_access import NSDAccess\n",
    "import scipy.io\n",
    "\n",
    "from config import NSD_ROOT_DIR, DATA_ROOT_DIR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "subject = 'subj02'\n",
    "atlasname = 'streams'\n",
    "atlasname = 'nsdgeneral'\n",
    "# atlasname = 'HCP_MMP1'\n",
    "\n",
    "# name : each or ave\n",
    "def write_index(sharedix, stims, name, save_dir):\n",
    "    feats = []\n",
    "    tr_idx = np.zeros(len(stims))\n",
    "    for idx, s in tqdm(enumerate(stims)): \n",
    "        if s in sharedix:\n",
    "            tr_idx[idx] = 0\n",
    "        else:\n",
    "            tr_idx[idx] = 1    \n",
    "        feats.append(s)\n",
    "    \n",
    "    feats = np.stack(feats)\n",
    "\n",
    "    feats_tr = feats[tr_idx==1]\n",
    "    feats_te = feats[tr_idx==0]\n",
    "    print(feats_tr.shape, feats_te.shape)\n",
    "\n",
    "    np.save(f'{save_dir}/index_{name}_tr.npy',feats_tr)\n",
    "    np.save(f'{save_dir}/index_{name}_te.npy',feats_te)\n",
    "\n",
    "nsda = NSDAccess(NSD_ROOT_DIR)\n",
    "nsd_expdesign = scipy.io.loadmat(os.path.join(NSD_ROOT_DIR, 'nsddata/experiments/nsd/nsd_expdesign.mat'))\n",
    "\n",
    "# Note that most of nsd_expdesign indices are 1-base index!\n",
    "# This is why subtracting 1\n",
    "sharedix = nsd_expdesign['sharedix'] -1 \n",
    "\n",
    "behs = pd.DataFrame()\n",
    "for i in range(1,38):\n",
    "    beh = nsda.read_behavior(subject=subject, \n",
    "                            session_index=i)\n",
    "    behs = pd.concat((behs,beh))\n",
    "\n",
    "# Caution: 73KID is 1-based! https://cvnlab.slite.page/p/fRv4lz5V2F/Behavioral-data\n",
    "stims_unique = behs['73KID'].unique() - 1\n",
    "stims_all = behs['73KID'] - 1\n",
    "\n",
    "savedir = os.path.join(DATA_ROOT_DIR, f'mrifeat/{subject}/')\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(f'{savedir}/{subject}_stims.npy'):\n",
    "    np.save(f'{savedir}/{subject}_stims.npy',stims_all)\n",
    "    np.save(f'{savedir}/{subject}_stims_ave.npy',stims_unique)\n",
    "\n",
    "write_index(sharedix, stims_all, 'each', savedir)\n",
    "write_index(sharedix, stims_unique, 'ave', savedir)\n",
    "# exit(0)\n",
    "\n",
    "atlas = nsda.read_atlas_results(subject=subject, atlas=atlasname, data_format='func1pt8mm')\n",
    "\n",
    "\n",
    "# 统计 atlas[0] > 0 的数量\n",
    "print(np.sum(atlas[0] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading betas: 100%|██████████| 37/37 [13:19<00:00, 21.60s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(1,38), desc = 'reading betas'):\n",
    "    beta_trial = nsda.read_betas(subject=subject, \n",
    "                            session_index=i, \n",
    "                            trial_index=[], # empty list as index means get all for this session\n",
    "                            data_type='betas_fithrf_GLMdenoise_RR',\n",
    "                            data_format='func1pt8mm')\n",
    "    if i==1:\n",
    "        betas_all = beta_trial\n",
    "    else:\n",
    "        betas_all = np.concatenate((betas_all,beta_trial),0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown 0\n",
      "SKIP\n",
      "nsdgeneral 1\n",
      "(27750, 14278)\n",
      "(9841, 14278)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr = []\n",
    "te = []\n",
    "ave_tr = []\n",
    "ave_te = []\n",
    "\n",
    "for roi,val in atlas[1].items():\n",
    "    print(roi,val)\n",
    "    if val == 0:\n",
    "        print('SKIP')\n",
    "        continue\n",
    "    else:\n",
    "        betas_roi = betas_all[:,atlas[0].transpose([2,1,0])==val]\n",
    "\n",
    "    print(betas_roi.shape)\n",
    "    \n",
    "    # Averaging for each stimulus\n",
    "    betas_roi_ave = []\n",
    "    for stim in stims_unique:\n",
    "        stim_mean = np.mean(betas_roi[stims_all == stim,:],axis=0)\n",
    "        betas_roi_ave.append(stim_mean)\n",
    "    betas_roi_ave = np.stack(betas_roi_ave)\n",
    "    print(betas_roi_ave.shape)\n",
    "    \n",
    "    # Train/Test Split\n",
    "    # ALLDATA\n",
    "    betas_tr = []\n",
    "    betas_te = []\n",
    "\n",
    "    for idx,stim in enumerate(stims_all):\n",
    "        if stim in sharedix:\n",
    "            betas_te.append(betas_roi[idx,:])\n",
    "        else:\n",
    "            betas_tr.append(betas_roi[idx,:])\n",
    "\n",
    "    betas_tr = np.stack(betas_tr)\n",
    "    betas_te = np.stack(betas_te)    \n",
    "    \n",
    "    # AVERAGED DATA        \n",
    "    betas_ave_tr = []\n",
    "    betas_ave_te = []\n",
    "    for idx,stim in enumerate(stims_unique):\n",
    "        if stim in sharedix:\n",
    "            betas_ave_te.append(betas_roi_ave[idx,:])\n",
    "        else:\n",
    "            betas_ave_tr.append(betas_roi_ave[idx,:])\n",
    "    betas_ave_tr = np.stack(betas_ave_tr)\n",
    "    betas_ave_te = np.stack(betas_ave_te)    \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    betas_tr = scaler.fit_transform(betas_tr)\n",
    "    betas_te = scaler.transform(betas_te)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    betas_ave_tr = scaler.fit_transform(betas_ave_tr)\n",
    "    betas_ave_te = scaler.transform(betas_ave_te)\n",
    "\n",
    "    tr.append(betas_tr)\n",
    "    te.append(betas_te)\n",
    "    ave_tr.append(betas_ave_tr)\n",
    "    ave_te.append(betas_ave_te)\n",
    "    \n",
    "    # Save\n",
    "    # np.save(f'{savedir}/{subject}_{roi}_betas_tr.npy',betas_tr)\n",
    "    # np.save(f'{savedir}/{subject}_{roi}_betas_te.npy',betas_te)\n",
    "    # np.save(f'{savedir}/{subject}_{roi}_betas_ave_tr.npy',betas_ave_tr)\n",
    "    # np.save(f'{savedir}/{subject}_{roi}_betas_ave_te.npy',betas_ave_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr = np.concatenate(tr, 1)\n",
    "te = np.concatenate(te, 1)\n",
    "ave_tr = np.concatenate(ave_tr, 1)\n",
    "ave_te = np.concatenate(ave_te, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr.shape (24980, 14278)\n",
      "te.shape (2770, 14278)\n",
      "ave_tr.shape (8859, 14278)\n",
      "ave_te.shape (982, 14278)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24980/24980 [05:06<00:00, 81.50it/s]\n",
      "100%|██████████| 2770/2770 [00:32<00:00, 84.95it/s]\n",
      "100%|██████████| 8859/8859 [01:55<00:00, 76.68it/s]\n",
      "100%|██████████| 982/982 [00:10<00:00, 89.70it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f'tr.shape {tr.shape}')\n",
    "print(f'te.shape {te.shape}')\n",
    "print(f'ave_tr.shape {ave_tr.shape}')\n",
    "print(f'ave_te.shape {ave_te.shape}')\n",
    "\n",
    "save_path = f'{savedir}/{atlasname}/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for i in tqdm(range(tr.shape[0])):\n",
    "    np.save(f'{save_path}/tr_{i:06}.npy', tr[i])\n",
    "for i in tqdm(range(te.shape[0])):\n",
    "    np.save(f'{save_path}/te_{i:06}.npy', te[i])\n",
    "for i in tqdm(range(ave_tr.shape[0])):\n",
    "    np.save(f'{save_path}/ave_tr_{i:06}.npy', ave_tr[i])\n",
    "for i in tqdm(range(ave_te.shape[0])):\n",
    "    np.save(f'{save_path}/ave_te_{i:06}.npy', ave_te[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
